{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FUuZLdgCnt4"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow.keras as keras\n",
        "# import tensorflow.keras.layers as layers\n",
        "# from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
        "import tensorflow_hub as hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDijzrUkCnt9",
        "outputId": "857db33c-604e-4e06-ac02-ccd7fa98f625"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# !ls /content/drive/MyDrive/CIP/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hji6lBcZv1_a"
      },
      "outputs": [],
      "source": [
        "# Set the image size\n",
        "IMAGE_SIZE = 240"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4d1uIW0Cnt9"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/CIP/\"\n",
        "labels = [\"edible\", \"poisonous\"]\n",
        "\n",
        "# Directories containing images for each category\n",
        "directory_group = [\n",
        "    [\"edible mushroom sporocarp\", \"edible sporocarp\"],\n",
        "    [\"poisonous mushroom sporocarp\", \"poisonous sporocarp\"]\n",
        "]\n",
        "\n",
        "edible_fungus = []\n",
        "poisonous_fungus = []\n",
        "\n",
        "# Define file paths for images in each category and add them to the corresponding list\n",
        "for label, directories in zip(labels, directory_group):\n",
        "    for directory in directories:\n",
        "        path = os.path.join(base_path, directory)\n",
        "        for file in os.listdir(path):\n",
        "            file_path = os.path.join(base_path, directory, file)\n",
        "            if label == \"edible\":\n",
        "                edible_fungus.append(file_path)\n",
        "            else:\n",
        "                poisonous_fungus.append(file_path)\n",
        "\n",
        "# Convert the file paths and labels to tensors separately\n",
        "edible_fungus = tf.constant(edible_fungus)\n",
        "edible_labels = tf.constant([0] * len(edible_fungus))\n",
        "poisonous_fungus = tf.constant(poisonous_fungus)\n",
        "poisonous_labels = tf.constant([1] * len(poisonous_fungus))\n",
        "\n",
        "# Combine the tensors for edible and poisonous fungus into a single tensor\n",
        "fungus_paths = tf.concat([edible_fungus, poisonous_fungus], axis=0)\n",
        "fungus_labels = tf.concat([edible_labels, poisonous_labels], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "# Define batch size and validation split\n",
        "batch_size = 32\n",
        "\n",
        "# Set number of epochs\n",
        "num_epochs = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1UVjg2XCnt_"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path, label):\n",
        "    # Read image file as a string\n",
        "    image_string = tf.io.read_file(image_path)\n",
        "    \n",
        "    # Decode the image based on the file type using a conditional statement\n",
        "    image_decoded = tf.cond(\n",
        "        tf.image.is_jpeg(image_string),  # Check if the image is a JPEG\n",
        "        lambda: tf.image.decode_jpeg(image_string, channels=3),  # Decode as JPEG, JPG\n",
        "        lambda: tf.image.decode_png(image_string, channels=3)    # Decode as PNG\n",
        "    )\n",
        "    \n",
        "    # Resize the decoded image\n",
        "    image_resized = tf.image.resize(image_decoded, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    \n",
        "    # Normalize the image pixels to be in the range [0, 1]\n",
        "    image_normalized = tf.cast(image_resized, tf.float32) / 255.0\n",
        "    \n",
        "    # Convert the label to an integer\n",
        "    label = tf.cast(label, tf.int64)\n",
        "    \n",
        "    return image_normalized, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAB0kPTtGMxR"
      },
      "outputs": [],
      "source": [
        "# Augmentation function\n",
        "def augment_image(image, label):\n",
        "\n",
        "    # Decode image from bytes format\n",
        "    image = _decode_image(image)\n",
        "\n",
        "    # Randomly flip the image horizontally\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "    # Randomly adjust the brightness of the image\n",
        "    image = tf.image.random_brightness(image, max_delta=0.05)\n",
        "\n",
        "    # Randomly adjust the contrast of the image\n",
        "    image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
        "\n",
        "    # Apply per-image standardization to the image\n",
        "    image = tf.image.per_image_standardization(image)\n",
        "\n",
        "    # Rotate the image randomly\n",
        "    image = tf.keras.preprocessing.image.random_rotation(image.numpy(), rg=5, row_axis=0, col_axis=1, channel_axis=2)\n",
        "    \n",
        "    # Apply random shearing to the image\n",
        "    image = tf.keras.preprocessing.image.random_shear(image.numpy(), intensity=0.1, row_axis=0, col_axis=1, channel_axis=2)\n",
        "    \n",
        "    # Apply random zoom to the image\n",
        "    image = tf.keras.preprocessing.image.random_zoom(image.numpy(), zoom_range=(0.9, 1.1), row_axis=0, col_axis=1, channel_axis=2)\n",
        "    \n",
        "    # Convert the image back to a tensor\n",
        "    image = tf.convert_to_tensor(image)\n",
        "    \n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BERg-LZLsm78"
      },
      "outputs": [],
      "source": [
        "# Decoding function\n",
        "def _decode_image(filename):\n",
        "    parts = tf.strings.split(filename, sep='.')\n",
        "    file_format = parts[-1]\n",
        "\n",
        "    # Read image file\n",
        "    image_string = tf.io.read_file(filename)\n",
        "\n",
        "    # Decode image based on file format\n",
        "    if file_format == 'jpeg' or file_format == 'jpg':\n",
        "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    elif file_format == 'png':\n",
        "        image_decoded = tf.image.decode_png(image_string, channels=3)\n",
        "    else:\n",
        "        raise ValueError('Unsupported image format: %s' % file_format)\n",
        "\n",
        "    # Cast image to float32 and resize\n",
        "    image = tf.cast(image_decoded, tf.float32)\n",
        "    image_resized = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "\n",
        "    return image_resized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF6Poa5DCnuA"
      },
      "outputs": [],
      "source": [
        "def get_dataset(image_paths, labels, batch_size, validation_split=0.2, test_split=0.1):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "\n",
        "    # Split into train and validation datasets\n",
        "    val_size = int(len(image_paths) * validation_split)\n",
        "    test_size = int(len(image_paths) * test_split)\n",
        "    train_size = len(image_paths) - val_size - test_size\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    remaining_dataset = dataset.skip(train_size)\n",
        "    test_dataset = remaining_dataset.take(test_size)\n",
        "    valid_dataset = remaining_dataset.skip(test_size)\n",
        "\n",
        "    # Apply augmentation function to train dataset\n",
        "    train_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    train_dataset = train_dataset.batch(batch_size)\n",
        "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # Apply preprocessing to validation and test datasets\n",
        "    preprocess = lambda image, label: (_decode_image(image), label)\n",
        "    valid_dataset = valid_dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    valid_dataset = valid_dataset.batch(batch_size)\n",
        "    valid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    test_dataset = test_dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    test_dataset = test_dataset.batch(batch_size)\n",
        "    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return train_dataset, valid_dataset, test_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIE0DkpnCnuG"
      },
      "source": [
        "# Model Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_yBHxYOVGMQ"
      },
      "outputs": [],
      "source": [
        "# Get datasets\n",
        "train_dataset, valid_dataset, test_dataset = get_dataset(fungus_paths, fungus_labels, batch_size, 0.2, 0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9D-6RYfvExy",
        "outputId": "d9186d9d-34d0-484d-978d-de6f6282053b"
      },
      "outputs": [],
      "source": [
        "for batch in train_dataset.take(1):\n",
        "    inputs, targets = batch\n",
        "    print(\"Inputs shape:\", inputs.shape)\n",
        "    print(\"Targets shape:\", targets.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxgvI8hXCnuK",
        "outputId": "ca427a0b-c353-4759-b693-d56bafc1dacd"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained ResNet model\n",
        "module_handle = \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature_vector/5\"\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(module_handle, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), trainable=False),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "# Print the original model summary\n",
        "model.summary()\n",
        "\n",
        "# Plot the model\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset, epochs=25, validation_data=valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "LLIHk8EzeTyO",
        "outputId": "f17eb210-20f5-4027-d345-6da778663dcb"
      },
      "outputs": [],
      "source": [
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Plot the model\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "QJyhx6OFev9_",
        "outputId": "28428df3-d170-448e-84f4-85f815140e74"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation accuracy\n",
        "plt.plot(history.history['binary_accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_binary_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjTS45Cg6L26"
      },
      "outputs": [],
      "source": [
        "# Save the model to Google Drive\n",
        "model_path = '/content/drive/MyDrive/model/saved_model'\n",
        "tf.keras.models.save_model(model, model_path, save_format='tf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA6UpCNtKZdr",
        "outputId": "41253c76-693a-4c1a-c414-07cfeba0ae8d"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cCqQO4uIeF1",
        "outputId": "8082d94b-1817-4ff9-f592-39fbceba29c6"
      },
      "outputs": [],
      "source": [
        "# Load an image\n",
        "image_path = \"/content/1280px-2006-10-25-amanita-muscaria-.crop.png\"\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
        "image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
        "image_array = tf.expand_dims(image_array, 0)  # Create a batch of 1 image\n",
        "\n",
        "# Predict the label of the image\n",
        "predictions = model.predict(image_array)\n",
        "class_names = [\"edible\", \"poisonous\"]\n",
        "predicted_label = class_names[predictions.argmax()]\n",
        "\n",
        "# Print the predicted label\n",
        "print(\"The predicted label of the image is:\", predicted_label)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
