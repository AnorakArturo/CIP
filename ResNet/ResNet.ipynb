{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "\n",
    "# from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "## ChatGPT Implementation of Pre-processing\n",
    "\n",
    "```Python\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "  \n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    directory='path/to/training/dataset',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "```\n",
    "\n",
    "### Useful URLs\n",
    "\n",
    "- [Intro to Keras for Engineers](https://keras.io/getting_started/intro_to_keras_for_engineers/)\n",
    "- [Image Classification from Scratch Example](https://keras.io/examples/vision/image_classification_from_scratch/)\n",
    "\n",
    "- [keras.io/getting_started](https://keras.io/getting_started/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "\n",
    "base_path = \"C:/Users/psaik/Documents/CIP/\"\n",
    "lables = [\"edible\", \"poisonous\"]\n",
    "\n",
    "# Directories containing images for each category\n",
    "directory_group = [\n",
    "    ['edible mushroom sporocarp', 'edible sporocarp'], \n",
    "    ['poisonous mushroom sporocarp', 'poisonous sporocarp']\n",
    "]\n",
    "\n",
    "# Lists to store file paths for each category\n",
    "edible_fungus = []\n",
    "poisonous_fungus = []\n",
    "\n",
    "# Loop through each directory and add file paths to corresponding category list\n",
    "for (label, directories) in zip(lables, directory_group):\n",
    "    for directory in directories:\n",
    "        items = os.listdir(base_path + directory)\n",
    "        for item in items:\n",
    "            file_path = base_path + directory + \"/\" + item\n",
    "            if label == \"edible\":\n",
    "                edible_fungus.append(file_path)\n",
    "            else:\n",
    "                poisonous_fungus.append(file_path)\n",
    "\n",
    "# Remove duplicate file paths and convert to lists\n",
    "edible_fungus = list(set(edible_fungus))\n",
    "poisonous_fungus = list(set(poisonous_fungus))\n",
    "\n",
    "# Define batch size and validation split\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "\n",
    "# Split data into training and validation sets\n",
    "edible_fungus_split_index = int((1 - validation_split) * len(edible_fungus))\n",
    "poisonous_fungus_split_index = int((1 - validation_split) * len(poisonous_fungus))\n",
    "train_edible_fungus, valid_edible_fungus = edible_fungus[:edible_fungus_split_index],  edible_fungus[edible_fungus_split_index:] \n",
    "train_poisonous_fungus, valid_poisonous_fungus = poisonous_fungus[:poisonous_fungus_split_index],  poisonous_fungus[poisonous_fungus_split_index:] \n",
    "\n",
    "# Print number of training and validation samples for each category\n",
    "print(len(train_edible_fungus), len(valid_edible_fungus))\n",
    "print(len(train_poisonous_fungus), len(valid_poisonous_fungus))\n",
    "\n",
    "# Calculate number of batches per epoch based on batch size\n",
    "num_batch_per_epoch = min(len(train_edible_fungus), len(train_poisonous_fungus)) // batch_size\n",
    "print(num_batch_per_epoch)\n",
    "\n",
    "# Set number of epochs and convert data to numpy arrays\n",
    "num_epochs = 50\n",
    "train_edible_fungus = np.array(train_edible_fungus)\n",
    "valid_edible_fungus = np.array(valid_edible_fungus)\n",
    "train_poisonous_fungus = np.array(train_poisonous_fungus)\n",
    "valid_poisonous_fungus = np.array(valid_poisonous_fungus)\n",
    "\n",
    "# Calculate total number of validation samples\n",
    "total_valid_count = len(valid_edible_fungus) + len(valid_poisonous_fungus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing function that reads and resizes images\n",
    "def preprocess_image(item):\n",
    "    # Read image file as a string\n",
    "    image_string = tf.io.read_file(item[0])\n",
    "    \n",
    "    # Decode the image based on the file type using a conditional statement\n",
    "    image_decoded = tf.cond(\n",
    "        tf.image.is_jpeg(image_string),  # Check if the image is a JPEG\n",
    "        lambda: tf.image.decode_jpeg(image_string, channels=3),  # Decode as JPEG, JPG\n",
    "        lambda: tf.image.decode_png(image_string, channels=3)    # Decode as PNG\n",
    "    )\n",
    "    \n",
    "    # Resize the decoded image\n",
    "    image_resized = tf.image.resize(image_decoded, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    \n",
    "    # Normalize the image pixels to be in the range [0, 1]\n",
    "    image_normalized = tf.cast(image_resized, tf.float32) / 255.0\n",
    "    \n",
    "    # Convert the label to an integer\n",
    "    label = tf.strings.to_number(item[1], tf.int64)\n",
    "    \n",
    "    return image_normalized, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and display an image from a file path\n",
    "def show_image(file_path, category):\n",
    "    img = tf.keras.preprocessing.image.load_img(file_path, target_size=(228, 228)) # Load image and resize to 228x228 pixels\n",
    "    plt.imshow(img) # Display the image\n",
    "    plt.title(category)\n",
    "    plt.show() # Show the plot\n",
    "\n",
    "import random\n",
    "random.seed(42) # Set a random seed for reproducibility\n",
    "\n",
    "random.shuffle(edible_fungus) # Shuffle the list of edible fungus image file paths randomly\n",
    "random.shuffle(poisonous_fungus)\n",
    "\n",
    "show_image(edible_fungus[0], 'edible') \n",
    "show_image(poisonous_fungus[0], 'poisonous')\n",
    "\n",
    "# from PIL import Image\n",
    "# def show_image(file_path, category):\n",
    "#     img = Image.open(file_path) # Load image using Pillow\n",
    "#     img = img.resize((228, 228)) # Resize to 228x228 pixels\n",
    "#     img.show() # External/Default image viewer\n",
    "#     print(category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Tensorflow dataset for training and evaluation\n",
    "# mode - train or eval, edible_fungus & poisonous_fungus - list of file paths\n",
    "def get_dataset(edible_fungus, poisonous_fungus, mode, batch_size):\n",
    "    # Combine into a single list\n",
    "    x = list(edible_fungus) + list(poisonous_fungus)\n",
    "    \n",
    "    # Create a binary label for each mushroom indicating whether it is poisonous or not\n",
    "    y = [0] * len(edible_fungus) + [1] * len(poisonous_fungus)\n",
    "    \n",
    "    # Combine the features and labels into a list of tuples\n",
    "    items = [(a, b) for (a, b) in zip(x, y)]\n",
    "    \n",
    "    # Create a TensorFlow dataset from the list of tuples, shuffle the items randomly, and batch the data\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(np.array(items)).shuffle(len(x))\n",
    "    dataset = dataset.map(preprocess_image).batch(batch_size)\n",
    "    \n",
    "    # Return the dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a balanced dataset\n",
    "def get_balanced_dataset(edible_fungus, poisonous_fungus, batch_count, batch_size, mode=\"train\"):\n",
    "    # Calc the number of samples per category\n",
    "    length_per_category = batch_size * batch_count // 2\n",
    "    # Randomly select indices of edible and poisonous fungi images\n",
    "    edible_indices = np.random.choice(len(edible_fungus), length_per_category)\n",
    "    poisonous_indices = np.random.choice(len(poisonous_fungus), length_per_category)\n",
    "    # Calculate the total sample count\n",
    "    sample_count = 2 * length_per_category\n",
    "    # Create a balanced dataset with the selected edible and poisonous fungi images\n",
    "    return get_dataset(\n",
    "        edible_fungus[edible_indices], \n",
    "        poisonous_fungus[poisonous_indices], \n",
    "        mode, \n",
    "        batch_size\n",
    "    ), sample_count\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edible_fungus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poisonous_fungus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
